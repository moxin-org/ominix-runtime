#include "utils.h"
#define STB_IMAGE_IMPLEMENTATION
#define STB_IMAGE_WRITE_IMPLEMENTATION
#define STB_IMAGE_RESIZE_IMPLEMENTATION

#include "stb/stb_image.h"
#include "stb/stb_image_resize2.h"
#include "stb/stb_image_write.h"

bool resize_normalize(const std::string &img_path, int target_h, int target_w,
                      const std::vector<float> &mean,
                      const std::vector<float> &std, std::vector<float> &out,
                      bool to_chw) {
  int width, height, channels;
  uint8_t *img_data =
      stbi_load(img_path.c_str(), &width, &height, &channels, 3);
  if (!img_data) {
    std::string error_msg = stbi_failure_reason();

    printf("%s: Failed to decode image %s: %s\n", __func__, img_path.c_str(),
           error_msg.c_str());
    return false;
  }

  std::vector<uint8_t> resized(target_w * target_h * 3);
  stbir_resize_uint8_linear(img_data, width, height, 0, resized.data(),
                            target_w, target_h, 0, STBIR_RGB);

  stbi_image_free(img_data);
  //   stbi_write_png("o.png", target_w, target_h, 3, resized.data(), 3 *
  //   target_w);

  out.resize(target_w * target_h * 3);
  if (to_chw) {
    for (int i = 0; i < target_h; ++i) {
      for (int j = 0; j < target_w; ++j) {
        for (int c = 0; c < 3; ++c) {
          int dst_idx = c * (target_w * target_h) + i * target_w + j;
          int idx = i * target_w * 3 + j * 3 + c;
          float val = resized[idx] / 255.0f;
          out[dst_idx] = (val - mean[c]) / std[c];
        }
      }
    }
  } else {
    for (int i = 0; i < target_w * target_h; ++i) {
      for (int c = 0; c < 3; c++) {
        int idx = i * 3 + c;
        float val = resized[idx] / 255.0f;
        out[idx] = (val - mean[c]) / std[c];
      }
    }
  }
  return true;
}

std::vector<std::string> split_text(const std::string &input,
                                    const std::string &delimiter) {
  std::vector<std::string> result;
  if (input.empty()) {
    return result;
  }
  size_t start = 0;
  size_t pos = 0;
  while ((pos = input.find(delimiter, start)) != std::string::npos) {
    if (pos > start) {
      result.push_back(input.substr(start, pos - start));
    }
    result.push_back(delimiter);
    start = pos + delimiter.length();
  }
  if (start < input.length()) {
    result.push_back(input.substr(start));
  }
  return result;
}

std::string string_format(const char *fmt, ...) {
  va_list ap;
  va_list ap2;
  va_start(ap, fmt);
  va_copy(ap2, ap);
  int size = vsnprintf(NULL, 0, fmt, ap);
  GGML_ASSERT(size >= 0 && size < INT_MAX); // NOLINT
  std::vector<char> buf(size + 1);
  int size2 = vsnprintf(buf.data(), size + 1, fmt, ap2);
  GGML_ASSERT(size2 == size);
  va_end(ap2);
  va_end(ap);
  return std::string(buf.data(), buf.size());
}

ggml_tensor *get_inp_tensor(ggml_cgraph *gf, const char *name) {
  ggml_tensor *inp = ggml_graph_get_tensor(gf, name);
  if (inp == nullptr) {
    GGML_ABORT("Failed to get tensor %s", name);
  }
  if (!(inp->flags & GGML_TENSOR_FLAG_INPUT)) {
    GGML_ABORT("Tensor %s is not an input tensor", name);
  }
  return inp;
}

void set_input_f32(ggml_cgraph *gf, const char *name,
                   const std::vector<float> &values) {
  ggml_tensor *cur = get_inp_tensor(gf, name);
  GGML_ASSERT(cur->type == GGML_TYPE_F32);
  GGML_ASSERT(ggml_nelements(cur) == (int64_t)values.size());
  ggml_backend_tensor_set(cur, values.data(), 0, ggml_nbytes(cur));
}

void set_input_i32(ggml_cgraph *gf, const char *name,
                   const std::vector<int32_t> &values) {
  ggml_tensor *cur = get_inp_tensor(gf, name);
  GGML_ASSERT(cur->type == GGML_TYPE_I32);
  GGML_ASSERT(ggml_nelements(cur) == (int64_t)values.size());
  ggml_backend_tensor_set(cur, values.data(), 0, ggml_nbytes(cur));
}

bool set_backend_threads(ggml_backend_t backend, int n_threads) {
  ggml_backend_dev_t dev = ggml_backend_get_device(backend);
  ggml_backend_reg_t reg = dev ? ggml_backend_dev_backend_reg(dev) : nullptr;
  if (reg) {
    auto ggml_backend_set_n_threads_fn =
        (ggml_backend_set_n_threads_t)ggml_backend_reg_get_proc_address(
            reg, "ggml_backend_set_n_threads");
    if (ggml_backend_set_n_threads_fn) {
      ggml_backend_set_n_threads_fn(backend, n_threads);
    }
  }
  // if(ggml_backend_is_cpu(backend)){
  //     ggml_backend_cpu_set_n_threads(backend, n_threads);
  // }
  return true;
}

ggml_tensor *get_tensor(ggml_context *ctx_meta, const std::string &name,
                        std::vector<ggml_tensor *> &tensors, bool required,
                        bool save) {
  ggml_tensor *cur = ggml_get_tensor(ctx_meta, name.c_str());
  if (!cur && required) {
    throw std::runtime_error(string_format("%s: unable to find tensor %s\n",
                                           __func__, name.c_str()));
  }
  if (cur && save) {
    tensors.push_back(cur);
  }

  return cur;
}